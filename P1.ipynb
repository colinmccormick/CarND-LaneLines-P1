{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project 1: **Finding Lane Lines on the Road** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import everything we'll need\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define key parameters\n",
    "\n",
    "output_dir = 'test_images_output/'\n",
    "test_image_dir = 'test_images/'\n",
    "\n",
    "gaussian_kernel_size = 5\n",
    "canny_low = 50\n",
    "canny_high = 150\n",
    "roi_h = 0.6\n",
    "roi_w1 = 0.47\n",
    "roi_w2 = 0.53\n",
    "hough_rho = 1\n",
    "hough_theta = np.pi/180\n",
    "hough_threshold = 32\n",
    "hough_min_len = 16\n",
    "hough_min_gap = 16\n",
    "slope_high = 1.0\n",
    "slope_low = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "\n",
    "def grayscale(img):\n",
    "    # Applies the Grayscale transform\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    # Applies the Canny transform\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    # Applies a Gaussian Noise kernel\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    # Applies an image mask\n",
    "    \n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):    # note: OpenCV\n",
    "    # Draws lines on an image. \n",
    "    # Note that color is defined as BRG in OpenCV, so need to modify if using OpenCV image open/write.\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    # Returns an image with hough lines drawn.\n",
    "\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    # Returns blended image as: initial_img * α + img * β + λ\n",
    "    \n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def hough_lines_extended(img, rho, theta, threshold, min_line_len, max_line_gap, slope_high, slope_low):\n",
    "    # Returns an image with extended lanes lines drawn based on average of hough lines\n",
    "\n",
    "    # set up\n",
    "    y_max,x_max,_ = im.shape\n",
    "    left_slopes = []\n",
    "    left_intercepts = []\n",
    "    right_slopes= []\n",
    "    right_intercepts = []\n",
    "\n",
    "    # detect lines\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), \n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    " \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            \n",
    "            # calculate slope and y-intercept using simple y = m*x + b formula\n",
    "            slope = (y2-y1) / float(x2-x1)\n",
    "            intercept = y1 - slope * x1\n",
    "                        \n",
    "            # reject slopes that are out of range (due to spurious lines in image)\n",
    "            if abs(slope) > slope_high or abs(slope) < slope_low:\n",
    "                continue\n",
    "                \n",
    "            # sort lines into right and left lanes by slope\n",
    "            # remember y = 0 at top of image, so right lane has slope > 0\n",
    "            if slope > 0:    \n",
    "                right_slopes.append(slope)\n",
    "                right_intercepts.append(intercept)\n",
    "            else:\n",
    "                left_slopes.append(slope)\n",
    "                left_intercepts.append(intercept)\n",
    "        \n",
    "    # calculate average values of slopes and intercepts\n",
    "    left_slope_average = sum(left_slopes) / float(len(left_slopes))\n",
    "    left_intercept_average = sum(left_intercepts) / float(len(left_intercepts))\n",
    "    right_slope_average = sum(right_slopes) / float(len(right_slopes))\n",
    "    right_intercept_average = sum(right_intercepts) / float(len(right_intercepts))\n",
    "\n",
    "    # calculate (x,y) coordinates for average lane lines\n",
    "    # lines begin at bottom of image and go to the top of the ROI\n",
    "    y_top = int( roi_h * y_max )\n",
    "    y_bottom = y_max\n",
    "    left_x_bottom = int( (y_bottom - left_intercept_average) / left_slope_average )\n",
    "    left_x_top = int( (y_top - left_intercept_average) / left_slope_average )\n",
    "    right_x_bottom = int( (y_bottom - right_intercept_average) / right_slope_average )\n",
    "    right_x_top = int( (y_top - right_intercept_average) / right_slope_average )\n",
    "        \n",
    "    # draw average lane lines\n",
    "    average_lines = [ [[left_x_bottom,y_bottom,left_x_top,y_top]], [[right_x_bottom,y_bottom,right_x_top,y_top]] ]\n",
    "    average_im = np.zeros((im.shape[0], im.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(average_im,average_lines,thickness = 8)\n",
    " \n",
    "    return average_im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define main image-processing pipeline\n",
    "    \n",
    "def process_image(im, individual_lines=False, save=False):\n",
    "    \n",
    "    # grayscale image and apply gaussian smoothing\n",
    "    gray = grayscale(im)\n",
    "    smoothed_gray = gaussian_blur(gray,gaussian_kernel_size)\n",
    "    \n",
    "    # find edges with canny\n",
    "    edges = canny(smoothed_gray,canny_low,canny_high)\n",
    "    \n",
    "    # create masked edges image with polygon mask\n",
    "    y_max,x_max,_ = im.shape\n",
    "    vertices = np.array([[ (0,y_max),(roi_w1*x_max,roi_h*y_max),\n",
    "                         (roi_w2*x_max,roi_h*y_max),(x_max,y_max) ]],dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges,vertices)\n",
    "    \n",
    "    # if looking for individual lines, use original hough helper function\n",
    "    # if looking for extended lane lines, use modified hough helper function\n",
    "    if individual_lines:\n",
    "        lines = hough_lines(masked_edges, hough_rho, hough_theta, \n",
    "                        hough_threshold, hough_min_len, hough_min_gap)\n",
    "    \n",
    "    else:\n",
    "        lines = hough_lines_extended(masked_edges, hough_rho, hough_theta, \n",
    "                        hough_threshold, hough_min_len, hough_min_gap, slope_high, slope_low)\n",
    " \n",
    "    # combine lines image with original image and save if specified\n",
    "    result = weighted_img(im, lines, α=0.8, β=1., λ=0.)\n",
    "    if save:\n",
    "        cv2.imwrite(os.path.join(output_dir,im_file),result)\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run lane line pipeline on each image in test dir to check if it works\n",
    "\n",
    "for im_file in os.listdir(test_image_dir):\n",
    "    \n",
    "    im = cv2.imread(os.path.join(test_image_dir,im_file))\n",
    "    process_image(im,individual_lines=True,save=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:05<00:00, 44.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 2.52 s, sys: 835 ms, total: 3.36 s\n",
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "# now test on a video\n",
    "\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now display the resulting video\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:18<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "CPU times: user 8.22 s, sys: 2.55 s, total: 10.8 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "# now test on a harder video!\n",
    "# this one has yellow lane lines in addition to white\n",
    "\n",
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "##clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now display the resulting video\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is testing an alternative approach to creating ROI-masked image\n",
    "\n",
    "def region_of_interest_modified(img, vertices):\n",
    "    # masks all pixels within vertices to be zero\n",
    "    \n",
    "    # work with a copy of the input image\n",
    "    masked_image = np.copy(img)\n",
    "        \n",
    "    # determine which color to fill the mask with depending on the input image channel number\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        mask_color = (0,) * channel_count\n",
    "    else:\n",
    "        mask_color = 0\n",
    " \n",
    "    # fill pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(masked_image, vertices, mask_color)\n",
    "    \n",
    "    return masked_image\n",
    "\n",
    "# run test\n",
    "\n",
    "for im_file in os.listdir(test_image_dir):\n",
    "    \n",
    "    # load image\n",
    "    im = cv2.imread(os.path.join(test_image_dir,im_file))\n",
    "    \n",
    "    # determine vertices\n",
    "    y_max,x_max,_ = im.shape\n",
    "    vertices = np.array([[ (0,0),(0,y_max),(roi_w1*x_max,roi_h*y_max),\n",
    "                         (roi_w2*x_max,roi_h*y_max),(x_max,y_max),(x_max,0) ]],dtype=np.int32)\n",
    "\n",
    "    result = region_of_interest_modified(im,vertices)\n",
    "\n",
    "    cv2.imwrite(os.path.join(output_dir,'ROI-'+im_file),result)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
